{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_reconst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe10acd3b7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mreconst_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mkl_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlog_var\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 两者相加得到总损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_reconst' is not defined"
     ]
    }
   ],
   "source": [
    "# 8.1 用变分自编码器生成图像\n",
    "# 8.1.2 变分自编码器\n",
    "# 度量图像的相似度一般采用交叉熵（如nn.BCELoss），\n",
    "# 度量两个分布的相似度一般采用KL散度（Kullback-Leibler divergence）。\n",
    "# 这两个度量的和构成了整个模型的损失函数\n",
    "\n",
    "# 定义重构损失函数及KL散度\n",
    "import torch.nn.functional as F\n",
    "\n",
    "reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "kl_div = -0.5*torch.sum(1+log_var - mu.pow(2) - log_var.exp())\n",
    "# 两者相加得到总损失\n",
    "loss = reconst_loss + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1.3 用变分自编码器生成图像\n",
    "# （1）导入必要的包\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)定义一些超参数\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 30\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3)对数据集进行预处理，如转换为Tensor，将数据集转换成循环，可批量加载的数据集\n",
    "# 下载MNIST训练集，如果需要下载，设置download=True将自动下载\n",
    "dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(),download=False)\n",
    "# 数据加载\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4)构建AVE模型，主要由Encode和Decode两部分组成\n",
    "# 定义AVE模型\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    # 用mu，log_var生成一个潜在空间点z，mu，log_var为两个统计参数，假设分布能生成图像\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self,z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) 选择GPU及优化器\n",
    "# 设置PyTorch在哪块GPU上运行\n",
    "#torch.cuda.set_device(1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5a256f34f68b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ave_samples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sampled-{}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 保存重构图像，即原图像通过解码器生成的图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "# 训练模型，同时保存原图像与随机生成的图像\n",
    "with torch.no_grad():\n",
    "    # 保存采样图像，即潜在向量z通过解码器生成新的图像\n",
    "    z = torch.randn(batch_size, z_dim).to(device)\n",
    "    out = model.decode(z).view(-1,1,28,28)\n",
    "    save_image(out, os.path.join('./ave_samples', 'sampled-{}.png').format(epoch+1))\n",
    "    # 保存重构图像，即原图像通过解码器生成的图像\n",
    "    out, _, _ = model(x)\n",
    "    x_concat = torch.cat([x.view(-1,1,28,28), out.view(-1,1,28,28)], dim=3)\n",
    "    save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f5034e5f3301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (7) 展示图像及重构图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreconsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./ave_samples/reconst-30.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 显示图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 不显示坐标轴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpimg' is not defined"
     ]
    }
   ],
   "source": [
    "# (7) 展示图像及重构图像\n",
    "reconsPath = './ave_samples/reconst-30.png'\n",
    "Image = mpimg.imread(reconsPath)\n",
    "plt.imshow(Image) # 显示图像\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3068a8e42b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (8)显示由潜在空间点Z生成的新图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./ave_samples/sampled-30.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 显示图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 不显示坐标轴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpimg' is not defined"
     ]
    }
   ],
   "source": [
    "# (8)显示由潜在空间点Z生成的新图像\n",
    "genPath = './ave_samples/sampled-30.png'\n",
    "Image = mpimg.imread(genPath)\n",
    "plt.imshow(Image) # 显示图像\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-39d91f802d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 8.2 GAN简介\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 定义判别器对真图像的损失函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "# 8.2 GAN简介\n",
    "# 定义判别器对真图像的损失函数\n",
    "outputs = D(images)\n",
    "d_loss_real = criterion(outputs, real_labels)\n",
    "real_score = outputs\n",
    "# 定义判别器对假图像（即由潜在空间点生成的图像）的损失函数\n",
    "z = torch.randn(batch_size, latent_size).to(device)\n",
    "fake_images = G(z)\n",
    "outputs = D(fake_images)\n",
    "d_loss_fake = criterion(outputs, fake_labels)\n",
    "fake_score = outputs\n",
    "# 得到判别器总的损失函数\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2c21808372a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 生成器的损失函数如何定义，才能使其越来越向真图像靠近？以真图像为标杆或标签即可\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'latent_size' is not defined"
     ]
    }
   ],
   "source": [
    "# 生成器的损失函数如何定义，才能使其越来越向真图像靠近？以真图像为标杆或标签即可\n",
    "z = torch.randn(batch_size, latent_size).to(device)\n",
    "fake_images = G(z)\n",
    "outputs = D(fake_images)\n",
    "g_loss = criterion(outputs, real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3用GAN生成图像\n",
    "# 8.3.1 判别器\n",
    "# 定义判别器网络结构，这里使用LeakyReLU为激活函数，输出一个节点并经过Sigmoid后输出，用于真假二分类\n",
    "\n",
    "# 构建判别器\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3.2 生成器\n",
    "# 生成器与AVE的生成器类似，不同的地方是输出为nn.tanh，\n",
    "# 使用nn.tanh将使数据分布在[-1,1]之间。其输入是潜在空间的向量z，输出维度与真图像相同\n",
    "\n",
    "# 构建生成器，相当于AVE中的解码器\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, image_size),\n",
    "    nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3.3 训练模型\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        # 定义图像是真或假的标签\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        # 训练判别器\n",
    "        # 定义判别器对真图像的损失函数\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        # 定义判别器对假图像（即由潜在空间点生成的图像）的损失函数\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        # 得到判别器总的损失函数\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        # 对生成器，判别器的梯度清零\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        # 在计算模型中所有张量的梯度后,调用optimizer.step()会使优化器迭代它应该更新的所有参数(张量),\n",
    "        # 并使用它们内部存储的grad来更新它们的值.\n",
    "        \"\"\"\n",
    "        optimizer.step()需要放在每一个batch训练中，而不是epoch训练中，\n",
    "        这是因为现在的mini-batch训练模式是假定每一个训练集就只有mini-batch这样大，\n",
    "        因此实际上可以将每一次mini-batch看做是一次训练，一次训练更新一次参数空间，因而optimizer.step()放在这里。\n",
    "\n",
    "        scheduler.step（）按照Pytorch的定义是用来更新优化器的学习率的，一般是按照epoch为单位进行更换，\n",
    "        即多少个epoch后更换一次学习率，因而scheduler.step()放在epoch这个大循环下\n",
    "        \"\"\"\n",
    "        if (i+1)%200==0:\n",
    "            print('Epoch[{}/{}],step[{}/{}],d_loss: {:.4f},g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
    "                 .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(),real_score.mean().item(),\n",
    "                         fake_score.mean().item()))\n",
    "        # 保存真图像\n",
    "        if(epoch+1) == 1:\n",
    "            images = images.reshape(images.size(0), 1, 28, 28)\n",
    "            save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "            # 保存假图像\n",
    "            fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "            save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_image-{}.png'.format(epoch+1)))\n",
    "        # 保存模型\n",
    "        torch.save(G.state_dict(), 'G.ckpt')\n",
    "        torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3.4 可视化结果\n",
    "reconsPath = './gan_samples/fake_images-200.png'\n",
    "Image = mpimg.imread(reconsPath)\n",
    "plt.imshow(Image) # 显示图片\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 ConditionGAN\n",
    "# 8.5.2 CGAN生成器\n",
    "# 定义生成器（Generator）及前向传播函数\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emp = nn.Embedding(10, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110,256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \"\"\"\n",
    "        inplace=True的意思是进行原地操作，\n",
    "        例如x=x+5，对x就是一个原地操作，y=x+5,x=y，完成了与x=x+5同样的功能但是不是原地操作，\n",
    "        上面LeakyReLU中的inplace=True的含义是一样的，\n",
    "        是对于Conv2d这样的上层网络传递下来的tensor直接进行修改，好处就是可以节省运算内存，不用多储存变量y\n",
    "        \"\"\"\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        z = z.view(z.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([z,c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.view(x.size(0), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.3 CGAN判别器\n",
    "# 定义判别器及前向传播函数\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794,1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.4)\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([x,c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.4 CGAN损失函数\n",
    "# 定义判别器对真实图像的损失函数\n",
    "real_validity = D(images, labels)\n",
    "d_loss_real = criterion(real_validity, real_labels)\n",
    "# 定义判别器对假图像（即由潜在空间点生成的图像）的损失函数\n",
    "z = torch.randn(batch_size, 100).to(device)\n",
    "fake_labels = torch.randint(0,10,(batch_size,)).to(device)\n",
    "fake_images = G(z, fake_labels)\n",
    "fake_validity = D(fake_images, fake_labels)\n",
    "d_loss_fake = criterion(fake_validity, torch.zeros(batch_size).to(device))\n",
    "# CGAN总的损失值\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.5 CGAN可视化\n",
    "# 利用网格（10×10）的形式显示指定条件下生成的图像\n",
    "from torchvision.utils import make_grid\n",
    "z = torch.randn(100, 100).to(device)\n",
    "labels = torch.LongTensor([i for i in range(10) for _ in range(10)]).to(device)\n",
    "images = G(z, labels).unsqueeze(1)\n",
    "grid = make_grid(images, nrow=10, normalize=True)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(grid.permute(1,2,0).detach().cpu.numpy(), cmap='binary')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.6 查看指定标签的数据\n",
    "# 可视化指定单个数字条件下生成的数字\n",
    "def generate_digit(generator, digit):\n",
    "    z = torch.randn(1,100).to(device)\n",
    "    label = torch.LongTensor([digit]).to(device)\n",
    "    img = generator(z, label).detach().cpu()\n",
    "    img = 0.5*img+0.5\n",
    "    return transforms.ToPILImage()(img)\n",
    "\n",
    "generate_digit(G, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.7 可视化损失值\n",
    "# 记录判别器、生成器的损失值代码\n",
    "writer.add_scalars('scalars', {'g_loss':g_loss, 'd_loss':d_loss}, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.6 DCGAN\n",
    "# 使用卷积层的判别器及使用转置卷积的生成器的一个具体代码\n",
    "\n",
    "# (1)使用卷积层，批规范层的判别器\n",
    "class Discrimibator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 输入大致为（nc）*64*64，nc表示通道数\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # ndf 表示判别器特征图的大小\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorma2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)使用转置卷积，批规范层的生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 输入Z， nz表示Z的大小\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            # ngf为生成器特征图大小\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False)\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4)*8*8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2)*16*16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # nc为通道数\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
