{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [0. 0. 1.]\n",
      "before_activation:  [0.6 0.5]\n",
      "状态值_0:  [0.53704957 0.46211716]\n",
      "输出值_0:  [1.56128388]\n",
      "state:  [0.53704957 0.46211716 2.        ]\n",
      "before_activation:  [1.2923401  1.39225678]\n",
      "状态值_1:  [0.85973818 0.88366641]\n",
      "输出值_1:  [2.72707101]\n"
     ]
    }
   ],
   "source": [
    "# 7.2 前向传播与随时间反向传播\n",
    "import numpy as np\n",
    "\n",
    "X = [1, 2]\n",
    "state = [0.0, 0.0]\n",
    "# np.array（默认情况下）将会copy该对象，而 np.asarray除非必要，否则不会copy该对象\n",
    "w_cell_state = np.asarray([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "b_cell = np.asarray([0.1, -0.1])\n",
    "w_output = np.asarray([[1.0], [2.0]])\n",
    "b_output = 0.1\n",
    "for i in range(len(X)):\n",
    "    state = np.append(state, X[i])\n",
    "    print(\"state: \", state)\n",
    "    before_activation = np.dot(state, w_cell_state) + b_cell\n",
    "    print(\"before_activation: \", before_activation)\n",
    "    state = np.tanh(before_activation)\n",
    "    print(\"状态值_%i: \"%i, state)\n",
    "    final_output = np.dot(state, w_output) + b_output\n",
    "    print(\"输出值_%i: \"%i, final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4 循环神经网络的PyTorch实现\n",
    "import torch\n",
    "from torch import nn\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RNN' object has no attribute 'weight_ih_10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5e5e3abf11ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 第一层相关权重参数形状\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wih形状{}，whh形状{}，bih形状{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RNN' object has no attribute 'weight_ih_10'"
     ]
    }
   ],
   "source": [
    "# 第一层相关权重参数形状\n",
    "print(\"wih形状{}，whh形状{}，bih形状{}\".format(rnn.weight_ih_10.shape,rnn.weight_hh_10.shape,rnn.bias_hh_10.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成传入数据\n",
    "input = torch.randn(100,32,10)\n",
    "h_0 = torch.randn(2,32,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 20]) torch.Size([2, 32, 20])\n"
     ]
    }
   ],
   "source": [
    "# 将输入数据传入RNN网络，将得到输出及更新后隐含状态值。\n",
    "#根据以上规则，输出output的形状应该是（100,32,20），隐含状态的输出形状应该与输入的形状一致\n",
    "output, h_n = rnn(input,h_0)\n",
    "print(output.shape,h_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_letters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7f7f7b5573bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mn_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_letters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_letters' is not defined"
     ]
    }
   ],
   "source": [
    "# 典型RNN网络的实现\n",
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM的PyTorch实现格式与RNN类似。下面定义一个和标准RNN相同的LSTM\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute 'weight_ih_10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7eca7a48d743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 第一层相关权重参数形状\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wih形状{}，whh形状{}，bih形状{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LSTM' object has no attribute 'weight_ih_10'"
     ]
    }
   ],
   "source": [
    "# 第一层相关权重参数形状\n",
    "print(\"wih形状{}，whh形状{}，bih形状{}\".format(lstm.weight_ih_10.shape, lstm.weight_hh_10.shape,lstm.bias_hh_10.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.1587e-01, -8.4987e-01,  1.3130e+00,  ...,  1.7248e-01,\n",
      "          -7.8895e-01,  1.1729e-01],\n",
      "         [-1.8492e+00,  1.5123e-02,  1.4559e+00,  ...,  7.6403e-01,\n",
      "          -4.1243e-01,  1.3712e+00],\n",
      "         [-7.1890e-01,  1.8856e+00, -8.6989e-01,  ..., -1.6453e+00,\n",
      "           6.2312e-01,  1.9659e+00],\n",
      "         ...,\n",
      "         [ 8.1415e-01, -2.9073e-01,  3.3207e-03,  ..., -3.1837e-01,\n",
      "          -7.1579e-01, -5.5601e-01],\n",
      "         [ 1.0837e+00,  9.0826e-01, -3.9673e-01,  ...,  3.2418e-01,\n",
      "          -1.3696e+00,  1.0265e+00],\n",
      "         [-3.4206e-01,  5.2908e-01,  7.6413e-01,  ..., -3.2378e-01,\n",
      "           1.1854e+00, -2.6113e-01]],\n",
      "\n",
      "        [[ 4.1697e-01, -1.1961e+00, -9.1395e-01,  ..., -8.9477e-01,\n",
      "           5.0036e-01,  6.7178e-01],\n",
      "         [-1.1315e+00, -1.0841e+00,  1.8855e+00,  ...,  7.9375e-01,\n",
      "           8.0231e-01,  2.6057e+00],\n",
      "         [-2.9889e-01,  2.1146e+00, -4.2866e-01,  ..., -6.8946e-01,\n",
      "          -1.8898e+00,  1.0270e+00],\n",
      "         ...,\n",
      "         [-4.8431e-01, -3.8085e-01, -7.8883e-01,  ...,  1.6617e+00,\n",
      "          -2.6576e-01, -4.1176e-01],\n",
      "         [ 6.5631e-01, -1.0396e+00, -3.5613e-01,  ...,  1.6405e-02,\n",
      "          -3.2454e-01, -8.8903e-01],\n",
      "         [-1.8678e-01,  9.2756e-01,  2.4295e-01,  ..., -1.1462e+00,\n",
      "           7.0549e-01,  9.7196e-02]],\n",
      "\n",
      "        [[-2.0676e+00, -1.2073e+00, -1.0986e+00,  ..., -1.3283e-01,\n",
      "          -8.6979e-01,  9.9480e-01],\n",
      "         [-1.4434e-01,  9.9146e-01, -6.7923e-01,  ..., -1.0219e+00,\n",
      "           1.4229e+00, -1.3589e+00],\n",
      "         [ 3.2056e-01, -8.6782e-01, -1.7734e+00,  ..., -5.7247e-01,\n",
      "          -3.2924e-01, -8.9402e-01],\n",
      "         ...,\n",
      "         [ 1.0568e+00, -7.8727e-01,  8.2442e-01,  ...,  6.9818e-01,\n",
      "           1.5274e-01,  4.7299e-01],\n",
      "         [-8.2412e-01,  2.8611e-01, -1.6086e-01,  ..., -1.6098e+00,\n",
      "           8.2494e-01, -9.9234e-01],\n",
      "         [-7.8025e-01,  6.5215e-01, -8.0342e-01,  ...,  7.9644e-01,\n",
      "           3.6857e-01,  7.5701e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1118e+00, -4.3612e-02, -1.3628e-01,  ...,  7.7892e-01,\n",
      "           7.3891e-01, -1.2111e+00],\n",
      "         [ 1.4140e+00,  2.7912e-01, -2.9047e-02,  ..., -1.1688e+00,\n",
      "           1.4793e+00, -7.6699e-01],\n",
      "         [-2.6985e-01,  7.7211e-02,  2.0933e+00,  ...,  6.7659e-02,\n",
      "          -1.2394e+00,  2.7469e-01],\n",
      "         ...,\n",
      "         [-1.1157e+00, -1.2873e+00, -1.1910e+00,  ..., -5.1716e-02,\n",
      "          -1.5014e+00,  5.7475e-01],\n",
      "         [ 1.5703e-01,  1.5327e+00,  9.5747e-01,  ..., -9.1718e-01,\n",
      "           1.9791e-01, -2.2213e-02],\n",
      "         [ 8.2146e-01, -1.1148e-01, -7.3178e-01,  ...,  1.5910e+00,\n",
      "          -5.6864e-01, -7.6730e-02]],\n",
      "\n",
      "        [[-1.1418e+00, -1.5435e-01, -3.0868e-01,  ..., -3.2766e-01,\n",
      "          -1.1115e+00, -1.5506e+00],\n",
      "         [-1.0678e+00,  4.1768e-01,  5.0105e-01,  ..., -4.6116e-01,\n",
      "          -1.5828e-01,  1.7846e-01],\n",
      "         [ 5.9222e-01, -7.0623e-01, -5.8854e-01,  ..., -1.0460e+00,\n",
      "           8.4960e-01,  8.0369e-01],\n",
      "         ...,\n",
      "         [ 1.6664e-01, -8.3070e-01,  4.4105e-01,  ..., -1.8982e+00,\n",
      "           7.5809e-02, -2.6056e-01],\n",
      "         [ 1.2077e+00,  4.7128e-01, -1.0237e+00,  ..., -3.4669e-01,\n",
      "           1.8403e+00,  9.7511e-01],\n",
      "         [-1.6057e+00, -4.3103e-02,  1.9728e+00,  ...,  2.0211e+00,\n",
      "           2.1846e-01,  1.6672e-02]],\n",
      "\n",
      "        [[ 2.0764e-01,  1.1273e+00,  1.6594e+00,  ..., -2.1098e+00,\n",
      "          -1.7871e-01, -4.5628e-01],\n",
      "         [-3.2588e-02,  5.5923e-01,  1.8721e-03,  ..., -1.3375e+00,\n",
      "          -1.2556e+00,  7.6236e-01],\n",
      "         [ 6.6856e-01,  2.4829e-01,  1.4124e+00,  ...,  9.3074e-01,\n",
      "          -1.2816e+00,  1.4202e+00],\n",
      "         ...,\n",
      "         [-1.4969e-01, -3.4004e-01,  1.5809e-01,  ...,  4.7071e-01,\n",
      "           1.0708e+00,  7.7617e-01],\n",
      "         [ 2.3946e+00,  2.1942e-01,  1.7427e+00,  ..., -1.8773e-01,\n",
      "           1.1923e+00,  1.9934e-01],\n",
      "         [ 1.9908e-01, -3.9845e-01,  1.3234e+00,  ...,  4.5190e-01,\n",
      "           1.2941e+00, -1.3256e+00]]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(100,32,10)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32, 20]) torch.Size([2, 32, 20]) torch.Size([2, 32, 20])\n"
     ]
    }
   ],
   "source": [
    "h0 = torch.randn(2,32,20)\n",
    "h0 = (h_0, h_0)\n",
    "output, h_n = lstm(input)\n",
    "print(output.size(), h_n[0].size(), h_n[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用PyTorch实现LSTM网络结构，该网络结构是一个LSTM单元，其输入是一个时间步\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, cell_size, output_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_size = cell_size\n",
    "        self.gate = nn.Linear(input_size + hidden_size, cell_size)\n",
    "        self.output = nn.Linear(hidden_size, output.size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        print(combined)\n",
    "        f_gate = self.sigmoid(self.gate(combined))\n",
    "        i_gate = self.sigmoid(self.gate(combined))\n",
    "        o_gate = self.sigmoid(self.gate(combined))\n",
    "        z_state = self.tanh(self.gate(combined))\n",
    "        cell = torch.add(torch.mul(cell, f_gate), torch.mul(z_state, i_gate))\n",
    "        hidden = torch.mul(self.tanh(cell), o_gate)\n",
    "        output = self.output(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,self.hidden_size)\n",
    "    \n",
    "    def initCell(self):\n",
    "        return torch.zeros(1,self.cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (builtin_function_or_method, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbuiltin_function_or_method\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbuiltin_function_or_method\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2aed7c023d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 实例化LSTMCell， 并传入输入，隐含状态等进行验证\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstmcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstmcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-9daa7a6460aa>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, hidden_size, cell_size, output_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (builtin_function_or_method, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbuiltin_function_or_method\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mbuiltin_function_or_method\u001b[0m, \u001b[31;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "# 实例化LSTMCell， 并传入输入，隐含状态等进行验证\n",
    "lstmcell = LSTMCell(input_size=10, hidden_size=20, cell_size=20, output_size=10)\n",
    "input = torch.randn(32,10)\n",
    "h_0 = torch.randn(32,20)\n",
    "output, hn, cn = lstmcell(input, h_0, h_0)\n",
    "print(output.size(), hn.size(), cn.size())\n",
    "# 不知道为什么错了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU实现\n",
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gate = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        z_gate = self.sigmoid(self.gate(combined))\n",
    "        r_gate = self.sigmoid(self.gate(combined))\n",
    "        combined01 = torch.cat((input, torch.mul(hidden, r_gate)), 1)\n",
    "        h1_state = self.tanh(self.gate(combined01))\n",
    "        h_state = torch.add(torch.mul((1-z_gate), hidden), torch.mul(h1_state, z_state))\n",
    "        output = self.output(h_state)\n",
    "        output = self.softmax(output)\n",
    "        return output, h_state\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 20], m2: [30 x 20] at /tmp/pip-req-build-4baxydiv/aten/src/TH/generic/THTensorMath.cpp:197",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-681489c59280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrucell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-f760151fb124>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mz_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mr_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcombined01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_gate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 20], m2: [30 x 20] at /tmp/pip-req-build-4baxydiv/aten/src/TH/generic/THTensorMath.cpp:197"
     ]
    }
   ],
   "source": [
    "grucell = GRUCell(input_size=10, hidden_size=20, output_size=10)\n",
    "input = torch.randn(32,10)\n",
    "h_0 = torch.randn(32,10)\n",
    "output, hn = grucell(input, h_0)\n",
    "print(output.size(), hn_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: jieba in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (0.42.1)\n"
     ]
    }
   ],
   "source": [
    "# 7.5 文本数据处理\n",
    "# 中文文本处理代码\n",
    "# （1）手机数据，定义停用词\n",
    "!pip install jieba\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.854 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['我', '爱', '上海', '他', '喜欢', '北京']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = \"\"\"我爱上海\n",
    "              他喜欢北京\"\"\"\n",
    "stoplist = [' ', '\\n'] # 停用词包括空格 回车符'\\n'\n",
    "# （2）利用jieba进行分词，并过滤停止词\n",
    "words = list(jieba.cut(raw_text))\n",
    "# 过滤停用词\n",
    "words = [i for i in words if i not in stoplist]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '喜欢', 1: '上海', 2: '他', 3: '北京', 4: '我', 5: '爱'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) 去重，然后对每个词机上索引或给一个整数\n",
    "word_to_ix = {i: word for i, word in enumerate(set(words))}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 1.7593,  0.7739, -0.4834, -0.2498, -0.8536,  0.1012,  1.4612, -0.4980]),\n",
       " tensor([ 0.2917, -0.6307,  1.4123, -0.8190,  0.4204, -1.9636,  1.3632,  0.2600]),\n",
       " tensor([ 0.7216, -2.2194,  0.1700, -0.2128, -0.8864,  0.1617, -1.8885,  0.6165]),\n",
       " tensor([ 1.3261, -1.3188,  0.0607, -1.8658, -1.4259,  0.7264, -0.8897, -0.8349]),\n",
       " tensor([-0.1918, -0.9072, -0.3972, -0.2820, -2.5001, -0.5284,  0.4714,  0.5085]),\n",
       " tensor([-0.0139, -0.6304, -1.0801, -2.2018,  1.3722,  0.7314, -0.8875, -2.0443])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) 词向量或者词嵌入\n",
    "# 采用PyTorch的nn.Embedding层，把整数转换为向量，参数为（词总数，向量长度）\n",
    "from torch import nn\n",
    "import torch\n",
    "embeds = nn.Embedding(6,8)\n",
    "lists = []\n",
    "for k,v in word_to_ix.items():\n",
    "    tensor_value = torch.tensor(k)\n",
    "    lists.append((embeds(tensor_value).data))\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6 词嵌入\n",
    "# 7.7 PyTorch实现词性判别\n",
    "# 使用LSTM网络实现\n",
    "# 7.7.2 数据预处理\n",
    "# 1.定义语句及词性\n",
    "# 定义训练数据\n",
    "training_data = [(\"The cat ate the fish\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "                 (\"They read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])]\n",
    "# 定义测试数据\n",
    "testing_data = [(\"They ate the fish\".split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'cat': 1, 'ate': 2, 'the': 3, 'fish': 4, 'They': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "# 构建每个单词的索引词典\n",
    "# 把每个单词用一个整数表示，将它们放在一个字典里。词性也如此\n",
    "word_to_ix = {} # 单词的索引字典\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "print(word_to_ix)\n",
    "# 两句话，共有9个不同单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手工设置词性的索引字典\n",
    "tag_to_ix = {\"DET\":0, \"NN\": 1, \"V\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.7.3 构建网络\n",
    "# 构建训练网络，共3层，分别为嵌入层、LSTM层、全连接层\n",
    "import torch.nn.functional as F\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    # 初始化隐含状态State及C\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1,1,self.hidden_dim),\n",
    "                torch.zeros(1,1,self.hidden_dim))\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        # 获得词嵌入矩阵embeds\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # 按照lstm格式，修改embeds的形状\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        # 修改隐含状态的形状，作为全连接层的输入\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        # 计算每个单词属于各词性的概率\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "# nn.LSTM层的输入形状为（序列长度，批量大小，输入的大小），\n",
    "# 序列长度就是时间步序列长度，这个长度是可变的。\n",
    "# F.log_softmax()执行的是一个Softmax回归的对数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据转换为模型要求的格式，即把输入数据需要转换为torch.LongTensor张量\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.7.4 训练网络\n",
    "# 1.定义几个超参数，实例化模型， 选择损失函数，优化器等\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_DIM=3 # 这里等于词性个数\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cat', 'ate', 'the', 'fish']\n",
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[-0.8667, -1.6864, -0.9302],\n",
      "        [-1.1116, -1.5773, -0.7669],\n",
      "        [-1.2992, -1.6199, -0.6361],\n",
      "        [-1.0136, -1.7322, -0.7761],\n",
      "        [-0.9497, -1.8066, -0.8009]], grad_fn=<LogSoftmaxBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.8667, -0.7669, -0.6361, -0.7761, -0.8009], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 2, 2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "# 2.简单运行一次\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "print(training_data[0][0])\n",
    "print(inputs)\n",
    "print(tag_scores)\n",
    "print(torch.max(tag_scores, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cat', 'ate', 'the', 'fish']\n",
      "tensor([[-0.0148, -5.8008, -4.4526],\n",
      "        [-5.2079, -0.0174, -4.4413],\n",
      "        [-5.8296, -3.7458, -0.0269],\n",
      "        [-0.0308, -3.9171, -4.5655],\n",
      "        [-4.7118, -0.0306, -3.8546]], grad_fn=<LogSoftmaxBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.0148, -0.0174, -0.0269, -0.0308, -0.0306], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 1, 2, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "# 下面我们循环多次训练该模型，精度将大大提升\n",
    "# 3.训练模型\n",
    "for epoch in range(400):\n",
    "    for sentence, tags in training_data:\n",
    "        # 清除网络先前的梯度值\n",
    "        model.zero_grad()\n",
    "        # 重新初始化隐藏层数据\n",
    "        model.hidden = model.init_hidden()\n",
    "        # 按照网络要求的格式处理输入数据和真实标签数据\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        # 实例化模型\n",
    "        tag_scores = model(sentence_in)\n",
    "        # 计算损失，反向传播梯度及更新参数模型\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 查看模型训练的结果\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "print(training_data[0][0])\n",
    "print(tag_scores)\n",
    "print(torch.max(tag_scores, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'ate', 'the', 'fish']\n",
      "tensor([5, 2, 3, 4])\n",
      "tensor([[-6.8843, -0.0112, -4.5961],\n",
      "        [-5.7666, -3.6306, -0.0301],\n",
      "        [-0.0308, -3.8895, -4.6186],\n",
      "        [-4.7095, -0.0300, -3.8864]], grad_fn=<LogSoftmaxBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.0112, -0.0301, -0.0308, -0.0300], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 2, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "# 7.7.5 测试模型\n",
    "test_inputs = prepare_sequence(testing_data[0], word_to_ix)\n",
    "tag_scores01 = model(test_inputs)\n",
    "print(testing_data[0])\n",
    "print(test_inputs)\n",
    "print(tag_scores01)\n",
    "print(torch.max(tag_scores01,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: tushare in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (1.2.59)\n",
      "Requirement already satisfied: lxml>=3.8.0 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from tushare) (4.5.0)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from tushare) (3.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.57.0 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from tushare) (0.57.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from tushare) (2.23.0)\n",
      "Requirement already satisfied: bs4>=0.0.1 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from tushare) (0.0.1)\n",
      "Requirement already satisfied: six in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from websocket-client>=0.57.0->tushare) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from requests>=2.0.0->tushare) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from requests>=2.0.0->tushare) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from requests>=2.0.0->tushare) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from requests>=2.0.0->tushare) (2.9)\n",
      "Requirement already satisfied: beautifulsoup4 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from bs4>=0.0.1->tushare) (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from beautifulsoup4->bs4>=0.0.1->tushare) (2.0)\n",
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: pandas in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (1.0.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/anaconda3/envs/env_1/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# 7.8 用LSTM预测股票行情\n",
    "# 7.8.1 导入数据\n",
    "!pip install tushare\n",
    "!pip install pandas\n",
    "import tushare as ts\n",
    "# 建立连接\n",
    "cons = ts.get_apis()\n",
    "# 获取沪深指数（000300）的信息，包括交易日期（datatime），开盘价（open）， 收盘价（close）\n",
    "# 最高价（high），最低价（low），成交量（vol），成交金额（amount），涨跌幅（p_change）\n",
    "df = ts.bar(\"000300\",conn=cons, asset=\"INDEX\",start_date='2010-01-01',end_date='')\n",
    "# 删除有null值的行\n",
    "df = df.dropna()\n",
    "# 把df保存到sh300.csv文件中\n",
    "df.to_csv('data/sh300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code', 'open', 'close', 'high', 'low', 'vol', 'amount', 'p_change'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.8.2 数据概览\n",
    "# 1.查看下载数据的字段，统计信息等\n",
    "# 查看df涉及的列名\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>p_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2517.000000</td>\n",
       "      <td>2517.000000</td>\n",
       "      <td>2517.000000</td>\n",
       "      <td>2517.000000</td>\n",
       "      <td>2.517000e+03</td>\n",
       "      <td>2.517000e+03</td>\n",
       "      <td>2517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3170.062927</td>\n",
       "      <td>3172.790814</td>\n",
       "      <td>3197.576368</td>\n",
       "      <td>3143.447039</td>\n",
       "      <td>1.096348e+06</td>\n",
       "      <td>1.331209e+11</td>\n",
       "      <td>0.014926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>641.157151</td>\n",
       "      <td>641.383705</td>\n",
       "      <td>647.162536</td>\n",
       "      <td>632.902602</td>\n",
       "      <td>8.948333e+05</td>\n",
       "      <td>1.229683e+11</td>\n",
       "      <td>1.464661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2079.870000</td>\n",
       "      <td>2086.970000</td>\n",
       "      <td>2118.790000</td>\n",
       "      <td>2023.170000</td>\n",
       "      <td>5.877472e-39</td>\n",
       "      <td>5.877472e-39</td>\n",
       "      <td>-8.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2577.360000</td>\n",
       "      <td>2579.750000</td>\n",
       "      <td>2602.230000</td>\n",
       "      <td>2557.670000</td>\n",
       "      <td>5.866490e+05</td>\n",
       "      <td>6.302869e+10</td>\n",
       "      <td>-0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3216.690000</td>\n",
       "      <td>3218.800000</td>\n",
       "      <td>3243.790000</td>\n",
       "      <td>3188.490000</td>\n",
       "      <td>8.381070e+05</td>\n",
       "      <td>9.801436e+10</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3667.230000</td>\n",
       "      <td>3675.080000</td>\n",
       "      <td>3712.500000</td>\n",
       "      <td>3643.320000</td>\n",
       "      <td>1.222471e+06</td>\n",
       "      <td>1.462706e+11</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5379.470000</td>\n",
       "      <td>5353.750000</td>\n",
       "      <td>5380.430000</td>\n",
       "      <td>5283.090000</td>\n",
       "      <td>6.864391e+06</td>\n",
       "      <td>9.494980e+11</td>\n",
       "      <td>6.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open        close         high          low           vol  \\\n",
       "count  2517.000000  2517.000000  2517.000000  2517.000000  2.517000e+03   \n",
       "mean   3170.062927  3172.790814  3197.576368  3143.447039  1.096348e+06   \n",
       "std     641.157151   641.383705   647.162536   632.902602  8.948333e+05   \n",
       "min    2079.870000  2086.970000  2118.790000  2023.170000  5.877472e-39   \n",
       "25%    2577.360000  2579.750000  2602.230000  2557.670000  5.866490e+05   \n",
       "50%    3216.690000  3218.800000  3243.790000  3188.490000  8.381070e+05   \n",
       "75%    3667.230000  3675.080000  3712.500000  3643.320000  1.222471e+06   \n",
       "max    5379.470000  5353.750000  5380.430000  5283.090000  6.864391e+06   \n",
       "\n",
       "             amount     p_change  \n",
       "count  2.517000e+03  2517.000000  \n",
       "mean   1.331209e+11     0.014926  \n",
       "std    1.229683e+11     1.464661  \n",
       "min    5.877472e-39    -8.750000  \n",
       "25%    6.302869e+10    -0.640000  \n",
       "50%    9.801436e+10     0.020000  \n",
       "75%    1.462706e+11     0.700000  \n",
       "max    9.494980e+11     6.710000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看df的统计信息\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-789663bd8159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregister_matplotlib_converters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 获取训练数据，原始数据，索引等信息\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# 可视化最高价\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# 2.可视化最高价数据\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "# 获取训练数据，原始数据，索引等信息\n",
    "df, df_all,df_index = readData('high', n=n, train_end=train_end)\n",
    "# 可视化最高价\n",
    "df_all = np.array(df_all.tolist())\n",
    "plt.plot(df_index, df_all, label='real-data')\n",
    "plt.legend(loc = 'upper right')\n",
    "# 这个readData怎么弄得？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.8.3 预处理数据\n",
    "# 1.生成训练数据\n",
    "# 通过一个序列来生成一个31*（count（*）-train_end）矩阵（用于处理时序的数据）\n",
    "# 其中最后一列维标签数据，就是把当前的前n天作为参数，当天的数据作为label\n",
    "def generate_data_by_n_days(series, n, index=False):\n",
    "    if len(series)<=n:\n",
    "        raise Exception(\"The Length of series is %d, while affect by (n=%d).\"%(len(series), n))\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        df['c%d'%i] = series.tolist()[i:-(n-i)]\n",
    "    df['y'] = series.tolist()[n:]\n",
    "    if index:\n",
    "        df.index = series.index[n:]\n",
    "    return df\n",
    "\n",
    "# 参数n与上相同，train_end表示的是后面多少个数据作为测试集\n",
    "def readData(column='high', n=30, all_too=True, index=False, train_end=-500):\n",
    "    df = pd.read_csv(\"sh300.csv\", index_col=0)\n",
    "    # 以日期为索引\n",
    "    df.index = list(map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\"), df.index))\n",
    "    # 获取每天的最高价\n",
    "    df_column = df[column].copy()\n",
    "    # 拆分为训练集和测试集\n",
    "    df_column_train, df_column_test = df_column[:train_end], df_column[train_end - n:]\n",
    "    # 生成训练数据\n",
    "    df_generate_train = generate_data_by_n_days(df_column_train,n,index=index)\n",
    "    if all_too:\n",
    "        return df_generate_train, df_column, df.index.tolist()\n",
    "    return df_generate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c2ba7d3c1710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_numpy_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_numpy_sta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_numpy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_numpy_mean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf_numpy_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3335\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "# 2.规范化处理\n",
    "# 对数据进行预处理，规范化及转换为Tensor\n",
    "import numpy as np\n",
    "\n",
    "df_numpy = np.array(df)\n",
    "df_numpy_mean = np.mean(df_numpy)\n",
    "df_numpy_sta = np.std(df_numpy)\n",
    "df_numpy = (df_numpy - df_numpy_mean) / df_numpy_std\n",
    "df_tensor = torch.Tensor(df_numpy)\n",
    "trainset = mytrainset(df_tensor)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.8.4 定义模型\n",
    "# 使用LSTM网络，此时LSTM输出到一个全连接层\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = 64,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.out = nn.Sequential(nn.Linear(64, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None) #None即隐层状态用0初始化\n",
    "        out = self.out(r_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboardX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cd16b4d77456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 建立训练模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 记录损失值，并用tensorboardx在web上展示\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboardX'"
     ]
    }
   ],
   "source": [
    "# 7.8.5 训练模型\n",
    "# 建立训练模型\n",
    "# 记录损失值，并用tensorboardx在web上展示\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "rnn = RNN(n).to(device)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "for step in range(EPOCH):\n",
    "    for tx, ty in trainloader:\n",
    "        tx = tx.to(device)\n",
    "        ty = ty.to(device)\n",
    "        # 在第一个维度上添加一个维度为1的维度，形状变为[batch, seq_len, input_size]\n",
    "        output = rnn(torch.undqueeze(tx, dim=1)).to(device)\n",
    "        loss = loss_func(torch.sequeeze(output), ty)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    writer.add_scalar('sh300_loss', loss, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.8.6 测试模型\n",
    "# 1.使用测试数据，验证模型\n",
    "for i in range(n, len(df_all)):\n",
    "    x = df_all_normal_tensor[i-n:i].to(device)\n",
    "    # rnn的输入必须是3维， 故需要添加两个一维的维度，最后成为[1,1,input_size]\n",
    "    x = torch.unsqueeze(torch.unsqueeze(x,dim=0),dim=0)\n",
    "    y = rnn(x).to(device)\n",
    "    if i < test_index:\n",
    "        # detach用于切断反向传播\n",
    "        generate_data_train.append(torch.squeeze(y).detach().cpu().numpy()*df_numpy_std+df_numpy_mean)\n",
    "    else：\n",
    "        generate_data_test.append(torch.squeeze(y).detach().cpu(),numpy()*df_numpy_std+df_numpy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-29a60ae86844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'real-data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_data_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'generate_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_index' is not defined"
     ]
    }
   ],
   "source": [
    "# 2.查看预测数据与源数据\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(df_index[train_end:-500], df[train_end:-500], label='real-data')\n",
    "plt.plot(df_index[train_end:-500], generate_data_test[-600:-500], label='generate_test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
